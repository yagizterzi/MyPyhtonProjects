{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yagizterzi/MyPyhtonProjects/blob/main/BraTS2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "!pip install nilearn # install the nilearn library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Conv2D, UpSampling2D, MaxPooling2D, concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import nibabel as nib\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import backend as K\n",
        "import glob\n",
        "import skimage.io as io\n",
        "import skimage.color as color\n",
        "import random as r\n",
        "import math\n",
        "from nilearn import plotting # import the plotting module from nilearn\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjZxa4DWdQML",
        "outputId": "f936fc84-a392-41cf-9d84-38e655a25bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nilearn\n",
            "  Downloading nilearn-0.10.4-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.4.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nilearn) (4.9.4)\n",
            "Requirement already satisfied: nibabel>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nilearn) (24.1)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->nilearn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->nilearn) (1.16.0)\n",
            "Downloading nilearn-0.10.4-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nilearn\n",
            "Successfully installed nilearn-0.10.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgfxLvS_Rw6Y",
        "outputId": "82458a46-b7d2-4ac9-82b3-4c97c8cbe939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_from_folders(train_folder, validation_folder):\n",
        "    X_train, Y_train = [], []\n",
        "    X_val, Y_val = [], []\n",
        "\n",
        "    # Eğitim verileri\n",
        "    for filename in os.listdir(train_folder):\n",
        "        if filename.endswith('.nii'):\n",
        "            img_path = os.path.join(train_folder, filename)\n",
        "            img_data = nib.load(img_path).get_fdata()\n",
        "            img_data = img_data[:, :, img_data.shape[2] // 2]  # Orta dilimi al\n",
        "            img_data = cv.resize(img_data, (128, 128))  # Boyutlandır\n",
        "            img_data = img_data.astype(np.float32) / np.max(img_data)  # Normalizasyon\n",
        "            X_train.append(img_data)\n",
        "\n",
        "            # Maske yükleme\n",
        "            mask_path = os.path.join(train_folder, 'masks', filename)  # Maske klasörü\n",
        "            if os.path.exists(mask_path):\n",
        "                mask_data = nib.load(mask_path).get_fdata()\n",
        "                mask_data = mask_data[:, :, mask_data.shape[2] // 2]  # Orta dilimi al\n",
        "                mask_data = cv.resize(mask_data, (128, 128))  # Boyutlandır\n",
        "                Y_train.append(mask_data)\n",
        "\n",
        "    # Doğrulama verileri\n",
        "    for filename in os.listdir(validation_folder):\n",
        "        if filename.endswith('.nii'):\n",
        "            img_path = os.path.join(validation_folder, filename)\n",
        "            img_data = nib.load(img_path).get_fdata()\n",
        "            img_data = img_data[:, :, img_data.shape[2] // 2]  # Orta dilimi al\n",
        "            img_data = cv.resize(img_data, (128, 128))  # Boyutlandır\n",
        "            img_data = img_data.astype(np.float32) / np.max(img_data)  # Normalizasyon\n",
        "            X_val.append(img_data)\n",
        "\n",
        "            # Maske yükleme\n",
        "            mask_path = os.path.join(validation_folder, 'masks', filename)\n",
        "            if os.path.exists(mask_path):\n",
        "                mask_data = nib.load(mask_path).get_fdata()\n",
        "                mask_data = mask_data[:, :, mask_data.shape[2] // 2]  # Orta dilimi al\n",
        "                mask_data = cv.resize(mask_data, (128, 128))  # Boyutlandır\n",
        "                Y_val.append(mask_data)\n",
        "\n",
        "    return np.array(X_train), np.array(Y_train), np.array(X_val), np.array(Y_val)\n",
        "\n",
        "# Klasör yollarını belirt (Google Drive'daki yollar)\n",
        "train_folder = '/content/drive/My Drive/path_to_your_train_folder'  # Eğitim verileri\n",
        "validation_folder = '/content/drive/My Drive/path_to_your_validation_folder'  # Doğrulama verileri\n",
        "\n",
        "X_train, Y_train, X_val, Y_val = load_data_from_folders(train_folder, validation_folder)\n",
        "\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('Y_train shape:', Y_train.shape)\n",
        "print('X_val shape:', X_val.shape)\n",
        "print('Y_val shape:', Y_val.shape)"
      ],
      "metadata": {
        "id": "gqlBGQ-LS2nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_model(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = Conv2D(64, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(128, (3, 3), padding='same', activation='relu')(p1)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(256, (3, 3), padding='same', activation='relu')(p2)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    # Bottleneck\n",
        "    c4 = Conv2D(512, (3, 3), padding='same', activation='relu')(p3)\n",
        "\n",
        "    # Decoder\n",
        "    u5 = UpSampling2D((2, 2))(c4)\n",
        "    u5 = concatenate([u5, c3])\n",
        "    c5 = Conv2D(256, (3, 3), padding='same', activation='relu')(u5)\n",
        "\n",
        "    u6 = UpSampling2D((2, 2))(c5)\n",
        "    u6 = concatenate([u6, c2])\n",
        "    c6 = Conv2D(128, (3, 3), padding='same', activation='relu')(u6)\n",
        "\n",
        "    u7 = UpSampling2D((2, 2))(c6)\n",
        "    u7 = concatenate([u7, c1])\n",
        "    c7 = Conv2D(64, (3, 3), padding='same', activation='relu')(u7)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c7)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "# Modeli tanımla\n",
        "input_shape = (128, 128, 1)  # Giriş boyutu\n",
        "model = unet_model(input_shape)\n",
        "\n",
        "# Modeli derle\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Modeli eğit\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "history = model.fit(X_train.reshape(-1, 128, 128, 1), Y_train.reshape(-1, 128, 128, 1),\n",
        "                    validation_data=(X_val.reshape(-1, 128, 128, 1), Y_val.reshape(-1, 128, 128, 1)),\n",
        "                    epochs=20, batch_size=16, callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "6MGb1mm4RdSN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}